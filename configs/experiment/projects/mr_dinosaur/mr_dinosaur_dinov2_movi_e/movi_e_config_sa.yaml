# @package _global_
defaults:
  - /experiment/projects/mr_dinosaur/mr_dinosaur_dinov2_movi_e/_base_feature_recon_sa
  - /dataset: movi_e_with_pseudo
  - /experiment/projects/mr_dinosaur/mr_dinosaur_dinov2_movi_e/_preprocessing_movi_e_dino_feature_recon_ccrop
  - /experiment/projects/mr_dinosaur/mr_dinosaur_dinov2_movi_e/_metrics_movi_e
  - _self_

trainer:
  devices: 1
  max_epochs: 15
  logger: tensorboard
  check_val_every_n_epoch: 1000
  callbacks: 
    - ${experiment.callbacks.model_checkpoint}
  enable_checkpointing: true 
  num_sanity_val_steps: 0
training_vis_frequency: 100
dataset:
  num_workers: 4
  batch_size: 8

experiment:
  input_feature_dim: 768
  callbacks:
    model_checkpoint:
      _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: checkpoints 
      filename: "model-{epoch:03d}-{step:06d}"  
      save_top_k: -1  
      every_n_epochs: 1 
      save_on_train_epoch_end: true 

models:
  conditioning:
    _target_: routed.ocl.conditioning.RandomConditioning
    n_slots: 24
    object_dim: 128
    batch_size_path: input.batch_size
  feature_extractor:
    _target_: routed.ocl.feature_extractors.DINOv2FeatureExtractor
    freeze: true
    feature_level: [11]
    video_path: input.image
  object_decoder:
    _target_: routed.ocl.decoding.PatchDecoder
    object_dim: ${models.perceptual_grouping.object_dim}
    output_dim: ${experiment.input_feature_dim}
    num_patches: 361
    object_features_path: perceptual_grouping.objects
    target_path: feature_extractor.features
    image_path: input.image
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [1024, 1024, 1024]
visualizations:
  pseudo_mask:
    _target_: routed.ocl.visualizations.PseudoMask
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: input.binary_instance_maps
optimizers:
  opt0:
    _target_: ocl.optimization.OptimizationWrapper
    optimizer:
      _target_: torch.optim.Adam
      _partial_: true
      lr: 0.000004
    lr_scheduler:
      _target_: ocl.scheduling.exponential_decay_after_optional_warmup
      _partial_: true
      decay_rate: 1
      decay_steps: 1
      warmup_steps: 0
seed: 0
load_checkpoint: null