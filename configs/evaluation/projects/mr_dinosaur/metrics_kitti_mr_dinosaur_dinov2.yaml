# @package _global_
defaults:
  - /evaluation_config
  - /dataset: kitti
  - _self_

eval_batch_size: 4  # Needs to match number of windows

modules:
  masks_resized:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: object_decoder.masks
    size: [378, 378]
    patch_mode: true
    channels_last: false
  masks_joined:
    _target_: routed.ocl.utils.windows.JoinWindows
    n_windows: 4
    masks_path: masks_resized
    keys_path: input.__key__
    size: [378, 1260]
  masks_merged:
    _target_: routed.ocl.utils.windows.MergeWindows
    n_windows: 4
    similarity: 0.2
    masks_path: masks_joined
    slot_features_path: object_decoder.slot_features
    keys_path: input.__key__
    size: [378, 378]
  masks_merged_resized:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: masks_merged
    size: [95, 315]
    resize_mode: "nearest"
  target_masks:
    _target_: routed.ocl.utils.windows.DropBatchDims
    dim_keep_start: 0
    dim_keep_end: 1
    inp_path: input.instance_mask
  target_masks_resized:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: target_masks
    size: [95, 315]
    resize_mode: "nearest"
evaluation_metrics:
  fg_ari:
    _target_: routed.ocl.metrics.ARIMetric
    prediction_path: masks_merged_resized
    target_path: target_masks_resized
    foreground: true
    combination_num: 4
  all_ari:
    _target_: routed.ocl.metrics.ARIMetric
    prediction_path: masks_merged_resized
    target_path: target_masks_resized
    foreground: false
    combination_num: 4
  F1@50:
    _target_: routed.ocl.metrics.APandARMetric
    prediction_path: masks_merged_resized
    target_path: target_masks_resized
    combination_num: 4
  AP50:
    _target_: routed.ocl.metrics.APandARMetric
    prediction_path: masks_merged_resized
    target_path: target_masks_resized
    combination_num: 4
    ap: true
  AR50:
    _target_: routed.ocl.metrics.APandARMetric
    prediction_path: masks_merged_resized
    target_path: target_masks_resized
    combination_num: 4
    ar: true

dataset:
  eval_transforms:
    # Resize images into one single shape before applying the sliding window
    02a_pre_resize:
      _target_: ocl.transforms.SimpleTransform
      batch_transform: false
      transforms:
        image:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Resize
              _convert_: all
              size: [378, 1260]
              interpolation: "${torchvision_interpolation_mode:BICUBIC}"
            - "${lambda_fn:'lambda image: image.clamp(0.0, 1.0)'}"  # Bicubic interpolation can get out of range
            - "${lambda_fn:'lambda v: v.permute(1, 2, 0).numpy()'}"
        instance_mask:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: ocl.preprocessing.MaskToTensor
            - _target_: ocl.preprocessing.ResizeNearestExact
              size: [378, 1260]

    # Apply sliding window, yielding several windows of the original image
    02b_sliding_window:
      _target_: ocl.transforms.SpatialSlidingWindow
      window_size: [378, 378]
      stride: [378, 378]
      padding: [126, 0, 126, 0]
      expected_n_windows: 4
      fields: ["image"]

    03b_preprocessing:
      _target_: ocl.transforms.SimpleTransform
      batch_transform: false
      transforms:
        image:
          # Preprocess each window for the network
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Resize
              size: 378
              interpolation: "${torchvision_interpolation_mode:BICUBIC}"
            - "${lambda_fn:'lambda image: image.clamp(0.0, 1.0)'}"  # Bicubic interpolation can get out of range
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]
